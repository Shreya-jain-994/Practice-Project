{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('census_income.csv')\n",
    "#Looking into top 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for maximum rows\n",
    "pd.set_option('display.max.rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns name\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking  total number columns and rows\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates rows\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking shape after removing duplicates\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we  remove 24 duplicates rows in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datatypes\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that there are two datatypes in our date set\n",
    "#Workclass,Education,Marital_status,Occupation,Relationship,Race,Sex ,Native_country,Income  are object datatype,\n",
    "#Age,Fnlwgt,Education_num,Capital_gain,Capital_loss,Hours_per_week are integer datypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Identifing the type of Problem- Output: Income.\n",
    "\n",
    "#As per problem statement label variable i.e. Income is object  value so we'll use classification to learn our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null values of each attributes\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that there is no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for null values if any, in heatmap\n",
    "sns.heatmap(data.isna())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that there is no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Statistics Summary\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see that  mean is more than median for all columns and large difference between standard deviation and maximum for capital_gain, capital_loss ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking value_counts of label\n",
    "data['Income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that dataset is imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that less than equal 50 K income is more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see that  question mark sign which as no meaning so we replace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Workclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that private work class is more that other workclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing quetion mark sign\n",
    "data['Workclass'].replace(' ?',data['Workclass'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Workclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8), facecolor='pink')\n",
    "sns.countplot(data['Education'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see that Hs-grad people more than other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see that Occupation feature has question mark so we removed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Occupation'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Occupation'].replace({' ?': ' Prof-specialty'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Marital_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,8), facecolor='blue')\n",
    "sns.countplot(data['Marital_status'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that Married-civ-spouse,Never-married  people have higher contribution of income compare than other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that Occupation has also present ? which has no meaning so we replace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Occupation'].replace({' ?':'Prof-specialty '},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,8), facecolor='yellow')\n",
    "sns.countplot(data['Occupation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Relationship'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that husband contribution is more comapre to other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Race'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we see that white has highest contribution to other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Sex'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that male has highest contribution for income compare than female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Native_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that Native_country has question mark sign obtaion which has no meaning so we remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Native_country'].replace(' ?',data['Native_country'].mode()[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we convert object into integer datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['Workclass','Education','Marital_status','Occupation','Relationship','Race','Sex' ,'Native_country','Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data['Workclass']=le.fit_transform(data['Workclass'])\n",
    "data['Education']=le.fit_transform(data['Education'])\n",
    "data['Marital_status']=le.fit_transform(data['Marital_status'])\n",
    "data['Occupation']=le.fit_transform(data['Occupation'])\n",
    "data['Relationship']=le.fit_transform(data['Relationship'])\n",
    "data['Race']=le.fit_transform(data['Race'])\n",
    "data['Sex']=le.fit_transform(data['Sex'])\n",
    "data['Native_country']=le.fit_transform(data['Native_country'])\n",
    "data['Income']=le.fit_transform(data['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot heatmap to visualize and find the coefficient of multicollinearity\n",
    "Correlation = data.corr()\n",
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can understanding properly as we use heatmap to find correleation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlation using Heat Map to get high and low correlated parameteres\n",
    "plt.figure(figsize=(15,13))\n",
    "sns.heatmap(Correlation,cmap='Blues',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that \n",
    "#Marital Status is highly negatively correlated to Income\n",
    "#Age is highly negatively correlated to Marital Status.\n",
    "#Marital Status is highly positively correlated to Relationship.\n",
    "#Income is highly positively correlated to Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with AveragePrice with respect to attributes\n",
    "data.corrwith(data.Income).plot.bar(\n",
    "        figsize = (20, 8), title = \"Correlation with Income Graph\", fontsize = 12,rot = 30, grid = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that age,education,education_num, occupation, race, sex, capital_gain,loss, hours_per_week has positive corelation with income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing Pairplot\n",
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In pairplot we cannot understand properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Age\",y=\"Income\",data=data)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist=data.columns.values\n",
    "for i in range(1,len(collist)):\n",
    "    plt.figure(figsize = (10,6))\n",
    "    sns.regplot(data[collist[i]], data['Income'])\n",
    "    plt.title('Scatter Plot of Income vs %s' %(collist[i]))\n",
    "    plt.xlabel(collist[i])\n",
    "    plt.ylabel('Income')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"Income\",y=\"Workclass\",data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Income'],data['Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(15,13), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=15 :     # as there are 15 columns in the data\n",
    "        ax = plt.subplot(3,5,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that outlier, skewness present in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z = np.abs(zscore(data))\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "new_data = data[(z<3).all(axis=1)]\n",
    "print(data.shape)\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here 5150 rows will be droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for how much data we lost\n",
    "loss_percent=(32536-27386)/32536*100\n",
    "print(loss_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(15,13), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in new_data:\n",
    "    if plotnumber<=15 :     # as there are 15 columns in the data\n",
    "        ax = plt.subplot(3,5,plotnumber)\n",
    "        sns.boxplot(new_data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Skewness has reduce significantly after outlier removal but still there is skewness present in the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing skewness\n",
    "new_data['Fnlwgt']=np.sqrt(new_data['Fnlwgt'])\n",
    "sns.histplot(new_data['Fnlwgt'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "new_data['Capital_loss']=np.sqrt(new_data['Capital_loss'])\n",
    "sns.histplot(new_data['Capital_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we split feature and label\n",
    "x=new_data.drop(\"Income\",axis=1)\n",
    "y=new_data[\"Income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we deal with data imbalance\n",
    "# Handiling class imbalance using SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros  = RandomOverSampler()\n",
    "X_new, y_new = ros.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_new.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "score =StandardScaler()\n",
    "X_score = score.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca =PCA()\n",
    "pca.fit_transform(X_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=12)\n",
    "new_pcomp=pca.fit_transform(X_score)\n",
    "princi_comp=pd.DataFrame(new_pcomp,columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12'])\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for best random state which give best accuracy\n",
    "# To find the best random state using logistic Regressor model\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,100):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(princi_comp,y_new,test_size=.30,random_state=i)\n",
    "    mod= LogisticRegression()\n",
    "    mod.fit(x_train,y_train)\n",
    "    pred=mod.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print ('best accuracy is',maxAccu,'on random state',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic model for training\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(x_train,y_train)\n",
    "\n",
    "log_score =log.score(x_train,y_train)\n",
    "\n",
    "print ('Logistic training Score ==>', log_score)\n",
    "\n",
    "log_pred = log.predict(x_test)\n",
    "\n",
    "log_cfm=confusion_matrix(y_test,log_pred)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test, log_pred))\n",
    "\n",
    "print(classification_report(y_test,log_pred))\n",
    "\n",
    "cvs=cross_val_score(LogisticRegression(),x,y,cv=5).mean()\n",
    "print(\"Cross_validation_score ----------\",cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SVC model for training\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "svc_score =log.score(x_train,y_train)\n",
    "\n",
    "print ('SVC training Score ==>', svc_score)\n",
    "\n",
    "svc_pred = svc.predict(x_test)\n",
    "\n",
    "svc_cfm=confusion_matrix(y_test,svc_pred)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test, svc_pred))\n",
    "\n",
    "print(classification_report(y_test,svc_pred))\n",
    "\n",
    "svc_cvs=cross_val_score(SVC(),x,y,cv=5).mean()\n",
    "print(\"Cross_validation_score ----------\",svc_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "knn_score = knn.score(x_train,y_train)\n",
    "\n",
    "print ('KNeighborsClassifier training Score ==>', knn_score)\n",
    "\n",
    "# Importing test set for prediction\n",
    "\n",
    "knn_pred = knn.predict(x_test)\n",
    "\n",
    "knn_cfm=confusion_matrix(y_test,knn_pred)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test,knn_pred))\n",
    "\n",
    "print(classification_report(y_test,knn_pred))\n",
    "\n",
    "knn_cvs = cross_val_score(KNeighborsClassifier(),x,y,cv=5).mean()\n",
    "\n",
    "print(\"Cross_validation_score ----------\",knn_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc=AdaBoostClassifier()\n",
    "\n",
    "abc.fit(x_train, y_train)\n",
    "\n",
    "abc_score = (abc.score(x_train, y_train))\n",
    "\n",
    "print('AdaBoostClassifier training Score ==>',abc_score)\n",
    "\n",
    "# Importing test set for prediction\n",
    "\n",
    "abc_pred = abc.predict(x_test)\n",
    "\n",
    "abc_cfm=confusion_matrix(y_test,abc_pred)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test,abc_pred))\n",
    "\n",
    "print(classification_report(y_test,abc_pred))\n",
    "\n",
    "abc_cvs = cross_val_score(AdaBoostClassifier(),x,y,cv=5).mean()\n",
    "\n",
    "print(\"Cross_validation_score ----------\",abc_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "dt_score = (decision_tree.score(x_train, y_train))\n",
    "\n",
    "print('Decision Tree training Score ==>',dt_score)\n",
    "\n",
    "# Importing test set for prediction\n",
    "\n",
    "dt_pred = decision_tree.predict(x_test)\n",
    "\n",
    "dt_cfm=confusion_matrix(y_test,dt_pred)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test,dt_pred))\n",
    "\n",
    "print(classification_report(y_test,dt_pred))\n",
    "\n",
    "dt_cvs = cross_val_score(DecisionTreeClassifier(),x,y,cv=5).mean()\n",
    "\n",
    "print(\"Cross_validation_score ----------\",dt_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "rfc_score = (rfc.score(x_train, y_train))\n",
    "\n",
    "print('Decision Tree training Score ==>',rfc_score)\n",
    "\n",
    "# Importing test set for prediction\n",
    "\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "\n",
    "print(\"Testing accuracy :\", accuracy_score(y_test,rfc_pred))\n",
    "\n",
    "rfc_cfm=confusion_matrix(y_test,dt_pred)\n",
    "\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "\n",
    "rfc_cvs = cross_val_score(rfc,x,y,cv=5).mean()\n",
    "\n",
    "print(\"Cross_validation_score ----------\",rfc_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we find ROC, AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,roc_auc_score,plot_roc_curve,roc_curve,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "roc_auc_score(y_test, log.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Classifier\n",
    "roc_auc_score(y_test,svc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier\n",
    "roc_auc_score(y_test,abc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "roc_auc_score(y_test,decision_tree.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "roc_auc_score(y_test,svc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check ROC, AUC Curve for the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(log, x_test, y_test)\n",
    "plot_roc_curve(knn, x_test, y_test, ax = disp.ax_) # ax_ = Axes with confusion matrix\n",
    "plot_roc_curve(decision_tree, x_test, y_test, ax = disp.ax_)\n",
    "plot_roc_curve(rfc, x_test, y_test, ax = disp.ax_)\n",
    "plot_roc_curve(svc, x_test, y_test, ax = disp.ax_)\n",
    "plot_roc_curve(abc, x_test, y_test, ax = disp.ax_)\n",
    "\n",
    "plt.legend(prop = {'size':11}, loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #we see that AdaBoostClassifier is best model and also give highest accuracy 86 before and after apply cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning the machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_grid={'n_estimators':[100,200,300],\n",
    "          'learning_rate':[0.001,0.01,0.1,0.5,0.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(AdaBoostClassifier(),para_grid)\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=abc.predict(x_test)\n",
    "cfm = confusion_matrix(y_test,y_predict)\n",
    "print(classification_report(y_test,y_predict, digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we conclude that AdaBoostClassifier is best model and also give highest accuracy 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import joblib \n",
    "joblib.dump(abc,\"census_income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
